<!doctype html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title>Classify emotions with Tensorflow.js</title> <meta name="author" content="Brendan Sudol"> <meta name="keywords" content=""> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="Classify emotions with Tensorflow.js"> <meta property="og:description" content="Classify emotions with Tensorflow.js"> <meta property="og:url" content="https://www.brendansudol.com/writing/tfjs-emotions"> <meta property="og:site_name" content="Brendan Sudol"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:title" content="Classify emotions with Tensorflow.js"> <meta name="twitter:description" content="Classify emotions with Tensorflow.js"> <meta name="twitter:url" content="https://www.brendansudol.com/writing/tfjs-emotions"> <meta name="twitter:image" content="https://www.brendansudol.com/assets/img/misc/bren-doodle-color.png"> <link rel="stylesheet" href="/assets/css/all.css?202012212327"> </head> <body class='site'> <header class='container mx-auto px2 py3 mb2 col-12'> <a href='/' class='h2 bold black mono js-name'>Brendan Sudol</a> </header> <div class='site-wrap'> <div class='container mx-auto px2'><div class="h6 gray">August 2018</div> <h1 class="mt0 mb3 h2 sm-h0">Classify emotions with Tensorflow.js</h1> <article class="mb3"><p>I finally got around to exploring Tensorflow.js, a JavaScript library for training and deploying machine learning models in the browser. The toy project I‚Äôm starting with is an image related task ‚Äì given a photo, classify the emotions of the people in it. Why this idea? When I‚Äôm on large video calls at work, there‚Äôs a grid view that shows everyone on the call and I‚Äôve often wished there was a way to quickly gauge how many people were happy / engaged at periodic times during the meeting. Now I can do that :)</p> <p><img src="/assets/img/writing/emotions.png" alt="Example" class="my3 border" /></p> <p><a href="https://brendansudol.com/faces/">https://brendansudol.com/faces/</a></p> <p>Here‚Äôs a brief rundown of the key components of this project:</p> <h4 id="image-prep">Image Prep</h4> <p>After uploading an photo but before it‚Äôs usable by the ML models, there are some preparatory steps. The image has to be converted to a <code class="highlighter-rouge">Tensor</code> of the appropriate shape and structure ‚Äì i.e., normalizing pixel values from [0, 255] to [-1, 1] and resizing dimensions to match the model parameters. In my case, I also had to convert color photos to grayscale (because the emotion model was trained on black and white images). These helper functions can be found <a href="https://github.com/brendansudol/faces/blob/master/src/ml/img.js">here</a>.</p> <h4 id="face-detection">Face detection</h4> <p>Before we can determine emotions, we have to find the people / faces in the image. For this, I‚Äôm utilizing <a href="https://github.com/justadudewhohacks/face-api.js">face-api.js</a>, a library built on top of Tensorflow.js for face detection / recognition. The library has a few models to choose from (i.e., SSD Mobilenet, Tiny Yolo); after some experimentation, I went with MTCNN (Multi-task Cascaded Convolutional Neural Networks). See <a href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/paper/spl.pdf">this paper</a> for more details; my very lightweight wrapper around this <code class="highlighter-rouge">face-api</code> model and utilities is <a href="https://github.com/brendansudol/faces/blob/master/src/ml/face.js">here</a>.</p> <h4 id="emotion-classification">Emotion classification</h4> <p>Now it‚Äôs time for the primary activity ‚Äì classifying emotions. For this, I‚Äôm using an <a href="https://github.com/oarriaga/face_classification">open-sourced CNN model</a> trained on the FER-2013 dataset, which contains images of faces categorized by one of seven emotional states (Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral). This model was built in Python, so I used this nifty <a href="https://github.com/tensorflow/tfjs-converter">tfjs-converter</a> tool to convert the Keras model to a web-friendly format. The code for that is <a href="https://github.com/brendansudol/faces/tree/master/py">here</a>.</p> <h4 id="wiring-up-front-end">Wiring up front-end</h4> <p>Finally, the site is wired up with React (main component <a href="https://github.com/brendansudol/faces/blob/master/src/components/App.js">here</a>). And for drawing the boxes around the faces and adding emojis to the image, I‚Äôm using an overlaid <code class="highlighter-rouge">&lt;canvas&gt;</code> element; one thing to note: the canvas must be cleared and redrawn if the image dimensions ever change (i.e., if you resize your browser window).</p> <p>That‚Äôs about it. Check it out and let me know what you think!</p> <p><a href="https://brendansudol.com/faces/">https://brendansudol.com/faces/</a></p> <p>üòÑüòêüôÅ</p> </article> </div> </div> <footer class="container mx-auto p2 mt4 col-12 h5 flex items-center"> <a class="mr2 black underline" href="/">Home</a> <a class="mr2 black underline" href="/writing/">Writing</a> <a class="mr2 black underline" href="https://github.com/brendansudol">Github</a> <a class="mr2 black underline" href="https://twitter.com/brensudol">Twitter</a> <a href="https://getwemoji.com/" target="_blank"> <img class="align-middle" src="/assets/img/misc/peace.gif" width="24" /> </a> </footer> <script type="text/javascript"> var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-37353161-5']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); </script> <script src="/assets/misc/fun.js"></script> </body> </html>
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_data                                                     train\n",
       "request_id                                             t3_l25d7\n",
       "title                   Request Colorado Springs Help Us Please\n",
       "body          Hi I am in need of food for my 4 children we a...\n",
       "got_pizza                                                     0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = {}\n",
    "for name in ['train', 'test']:\n",
    "    df = pd.read_json('../data/%s.json' % name)\n",
    "    df['_data'] = name\n",
    "    dfs[name] = df\n",
    "\n",
    "# combine train and test data into one df\n",
    "df = dfs['train'].append(dfs['test'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# limit to shared columns (plus predictor)\n",
    "cols = list(dfs['test'].columns) + ['requester_received_pizza']\n",
    "df = df[cols]\n",
    "\n",
    "# rename a few columns to be pithier\n",
    "df.rename(columns={\n",
    "        'request_title': 'title', \n",
    "        'request_text_edit_aware': 'body',\n",
    "        'requester_received_pizza': 'got_pizza',\n",
    "}, inplace=True)\n",
    "\n",
    "# convert got pizza indicator to ints\n",
    "df['got_pizza'] = df['got_pizza'].apply(lambda x: -1 if pd.isnull(x) else int(x))\n",
    "\n",
    "# toss out unused columns\n",
    "cols_to_keep = ['_data', 'request_id', 'title', 'body', 'got_pizza']\n",
    "df = df[cols_to_keep]\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request Colorado Springs Help Us Please\n",
      "--\n",
      "Hi I am in need of food for my 4 children we are a military family that has really hit hard times and we have exahusted all means of help just to be able to feed my family and make it through another night is all i ask i know our blessing is coming so whatever u can find in your heart to give is greatly appreciated\n",
      "--\n",
      "Request Colorado Springs Help Us Please Hi I am in need of food for my 4 children we are a military family that has really hit hard times and we have exahusted all means of help just to be able to feed my family and make it through another night is all i ask i know our blessing is coming so whatever u can find in your heart to give is greatly appreciated\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# combine title and body columns\n",
    "df['txt_raw'] = df['title'] + ' ' + df['body']\n",
    "\n",
    "# check that it worked\n",
    "for col in ['title', 'body', 'txt_raw']:\n",
    "    print df.iloc[0][col]\n",
    "    print '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request Colorado Springs Help Us Please Hi I am in need of food for my 4 children we are a military family that has really hit hard times and we have exahusted all means of help just to be able to feed my family and make it through another night is all i ask i know our blessing is coming so whatever u can find in your heart to give is greatly appreciated\n",
      "--\n",
      "request colorado springs help us please hi need food children military family really hit hard times exahusted means help able feed family make another night ask know blessing coming whatever u find heart give greatly appreciated\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# clean up text (lowercase, letters only, remove stop words)\n",
    "\n",
    "def clean_txt(raw, remove_stop=False):\n",
    "    # remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw) \n",
    "\n",
    "    # convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "\n",
    "    # remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # join cleaned words\n",
    "    return \" \".join(words)\n",
    "\n",
    "df['txt_clean'] = df['txt_raw'].apply(clean_txt)\n",
    "\n",
    "# check that it worked\n",
    "for col in ['txt_raw', 'txt_clean']:\n",
    "    print df.iloc[0][col]\n",
    "    print '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prep training set data for modeling\n",
    "# (creates numerical arrays for X (bag of words) and y (got pizza)\n",
    "\n",
    "def get_xy(vectorizer=None, txt_col='txt_clean'):\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "        \n",
    "    dg = df[df['_data'] == 'train']\n",
    "\n",
    "    X = vectorizer.fit_transform(dg[txt_col]).toarray()\n",
    "    y = dg['got_pizza'].astype(int).as_matrix()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.885149\n",
      "Accuracy on test data:     0.717822\n",
      "AUC: 0.512876\n"
     ]
    }
   ],
   "source": [
    "# randomly split training set and try default NB model\n",
    "\n",
    "X, y = get_xy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "print \"Accuracy on training data: %f\" % model.score(X_train, y_train)\n",
    "print \"Accuracy on test data:     %f\" % model.score(X_test, y_test)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print \"AUC: %f\" % auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# whoa, not very good - an roc auc just a little bit better\n",
    "# than random chance and a big difference in error rates\n",
    "# between training and test data implying overfitting\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5.000000\n",
      "min_df: 0.020000\n",
      "best auc: 0.605254\n"
     ]
    }
   ],
   "source": [
    "# let's calibrate some params (in vectorizer & classifier)\n",
    "# and choose values that maximize roc auc\n",
    "\n",
    "# the grid of params to search over\n",
    "alphas = [1, 5, 10, 25]\n",
    "min_dfs = [0.001, 0.01, 0.02, 0.05]\n",
    "\n",
    "# loop through values to find optimal settings\n",
    "best_alpha, best_min_df = None, None\n",
    "max_auc = -np.inf\n",
    "\n",
    "for alpha in alphas:\n",
    "    for min_df in min_dfs:\n",
    "        \n",
    "        vectorizer = CountVectorizer(min_df = min_df)\n",
    "\n",
    "        X, y = get_xy(vectorizer)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "\n",
    "        model = MultinomialNB(alpha=alpha).fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict_proba(X_test)[:, 1]        \n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        auc_val = auc(fpr, tpr)\n",
    "\n",
    "        if auc_val > max_auc:\n",
    "            max_auc = auc_val\n",
    "            best_alpha, best_min_df = alpha, min_df \n",
    "\n",
    "                \n",
    "print \"alpha: %f\" % best_alpha\n",
    "print \"min_df: %f\" % best_min_df\n",
    "print \"best auc: %f\" % max_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.757756\n",
      "Accuracy on test data:     0.724752\n"
     ]
    }
   ],
   "source": [
    "# let's make sure this new model is less over-fit\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = best_min_df)\n",
    "\n",
    "X, y = get_xy(vectorizer)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)\n",
    "\n",
    "model = MultinomialNB(alpha=best_alpha).fit(X_train, y_train)\n",
    "\n",
    "print \"Accuracy on training data: %f\" % model.score(X_train, y_train)\n",
    "print \"Accuracy on test data:     %f\" % model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     request_id  requester_received_pizza\n",
      "4040   t3_i8iy4                  0.325085\n",
      "4041  t3_1mfqi0                  0.545561\n",
      "4042   t3_lclka                  0.242250\n",
      "4043  t3_1jdgdj                  0.167956\n",
      "4044   t3_t2qt4                  0.142908\n"
     ]
    }
   ],
   "source": [
    "# finally, let's train on full training set with best params\n",
    "# and save our predictions for submission\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = best_min_df)\n",
    "\n",
    "X, y = get_xy(vectorizer)\n",
    "\n",
    "model = MultinomialNB(alpha=best_alpha).fit(X, y)\n",
    "\n",
    "df_test = df[df['_data'] == 'test'].copy()\n",
    "X_test = vectorizer.transform(df_test['txt_clean'])\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "df_test['requester_received_pizza'] = y_pred\n",
    "final_df = df_test[['request_id', 'requester_received_pizza']]\n",
    "\n",
    "# sanity check entries \n",
    "print final_df.head(5)\n",
    "\n",
    "# output predictions\n",
    "final_df.to_csv('../output/predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good words\n",
      "           word  P(pizza | word)\n",
      "161         jpg         0.427790\n",
      "268        rice         0.383345\n",
      "157       imgur         0.364823\n",
      "325       tight         0.363433\n",
      "141     helping         0.361993\n",
      "235      person         0.354807\n",
      "345  unemployed         0.344983\n",
      "231    paycheck         0.338030\n",
      "233      paying         0.337769\n",
      "50        check         0.336646\n",
      "\n",
      "---\n",
      "\n",
      "bad words\n",
      "         word  P(pizza | word)\n",
      "34   birthday         0.181946\n",
      "169     leave         0.180133\n",
      "104   florida         0.175216\n",
      "326      till         0.172488\n",
      "112   friends         0.165682\n",
      "20       area         0.162599\n",
      "108      free         0.159392\n",
      "285   sitting         0.159047\n",
      "307  studying         0.155792\n",
      "111    friend         0.143568\n"
     ]
    }
   ],
   "source": [
    "# and for funsies, let's see which words best predict getting a pizza \n",
    "\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "x = np.eye(X.shape[1])\n",
    "probs = model.predict_proba(x)[:, 1]\n",
    "\n",
    "word_df = pd.DataFrame()\n",
    "word_df['word'] = words\n",
    "word_df['P(pizza | word)'] = probs\n",
    "word_df.sort('P(pizza | word)', ascending=False, inplace=True)\n",
    "\n",
    "print 'good words'\n",
    "print word_df.head(10)\n",
    "print '\\n---\\n'\n",
    "print 'bad words'\n",
    "print word_df.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
